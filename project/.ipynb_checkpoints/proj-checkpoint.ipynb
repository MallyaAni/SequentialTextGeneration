{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/animallya/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.lm import Vocabulary\n",
    "import glob\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from gensim.models import Word2Vec\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagmap = {\n",
    "'CC': 'coordinating conjunction',\n",
    "'CD': 'cardinal digit',\n",
    "'DT': 'determiner',\n",
    "'EX': 'existential there (like: “there is” … think of it like “there exists”)',\n",
    "'FW': 'foreign word',\n",
    "'IN': 'preposition/subordinating conjunction',\n",
    "'JJ' :'adjective ‘big’',\n",
    "'JJR' :'adjective, comparative ‘bigger’',\n",
    "'JJS': 'adjective, superlative ‘biggest’',\n",
    "'LS': 'list marker 1)',\n",
    "'MD': 'modal could, will',\n",
    "'NN': 'noun, singular ‘desk',\n",
    "'NNS': 'noun plural ‘desks',\n",
    "'NNP': 'proper noun, singular ‘Harrison’',\n",
    "'NNPS':'proper noun, plural ‘Americans’',\n",
    "'PDT': 'predeterminer ‘all the kids’',\n",
    "'POS': 'possessive ending parent’s',\n",
    "'PRP': 'personal pronoun I, he, she',\n",
    "'PRP$':'possessive pronoun my, his, hers',\n",
    "'RB': 'adverb very, silently,',\n",
    "'RBR': 'adverb, comparative better',\n",
    "'RBS': 'adverb, superlative best',\n",
    "'RP': 'particle give up',\n",
    "'TO': 'to go ‘to’ the store.',\n",
    "'UH': 'interjection, errrrrrrrm',\n",
    "'VB': 'verb, base form take',\n",
    "'VBD': 'verb, past tense took',\n",
    "'VBG': 'verb, gerund/present participle taking',\n",
    "'VBN': 'verb, past participle taken',\n",
    "'VBP': 'verb, sing. present, non-3d take',\n",
    "'VBZ': 'verb, 3rd person sing. present takes',\n",
    "'WDT': 'wh-determiner which',\n",
    "'WP': 'wh-pronoun who, what',\n",
    "'WP$': 'possessive wh-pronoun whose',\n",
    "'WRB': 'wh-abverb where, when'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data .read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text\n",
    "\n",
    "corpus = article_text.lower()\n",
    "corpus = re.sub('[^a-zA-Z]', ' ', corpus)\n",
    "corpus = re.sub(r'\\s+', ' ', corpus)[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(corpus)\n",
    "vocab = Vocabulary(words)\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocab)\n",
    "X = vectorizer.fit_transform([corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams=list(ngrams(words,3))\n",
    "tags = [((nltk.pos_tag(t)[0])[1],(nltk.pos_tag(t)[1])[1], (nltk.pos_tag(t)[2])[1]) for t in trigrams]\n",
    "labels = [trigrams[i][0]for i in range(3,len(trigrams))]\n",
    "trigrams = trigrams[:-3]\n",
    "tags = tags[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in computer science artificial intelligence ai sometimes called machine intelligence is intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans leading ai textbooks define the field as the study of intelligent agents any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals colloquially the term artificial intelligence is often used to describe machines or computers that mimic cognitive functions that humans associate with the human mind such as learning and problem solving as machines become increasingly capable tasks considered to require intelligence are often removed from the definition of ai a phenomenon known as the ai effect a quip in tesler s theorem says ai is whatever hasn t been done yet for instance optical character recognition is frequently excluded from things considered to be ai having become a routine technology modern machine capabilities generally classified as a\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>tags</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(in, computer, science)</td>\n",
       "      <td>(IN, NN, NN)</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(computer, science, artificial)</td>\n",
       "      <td>(NN, NN, JJ)</td>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(science, artificial, intelligence)</td>\n",
       "      <td>(NN, JJ, NN)</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(artificial, intelligence, ai)</td>\n",
       "      <td>(JJ, NN, NN)</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(intelligence, ai, sometimes)</td>\n",
       "      <td>(NN, NN, RB)</td>\n",
       "      <td>called</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               trigram          tags          pred\n",
       "0              (in, computer, science)  (IN, NN, NN)    artificial\n",
       "1      (computer, science, artificial)  (NN, NN, JJ)  intelligence\n",
       "2  (science, artificial, intelligence)  (NN, JJ, NN)            ai\n",
       "3       (artificial, intelligence, ai)  (JJ, NN, NN)     sometimes\n",
       "4        (intelligence, ai, sometimes)  (NN, NN, RB)        called"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'trigram':trigrams, 'tags':tags, 'pred':labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram_('a', 'bad', 'overly')</th>\n",
       "      <th>trigram_('a', 'bayesian', 'network')</th>\n",
       "      <th>trigram_('a', 'best', 'guess')</th>\n",
       "      <th>trigram_('a', 'billion', 'dollars')</th>\n",
       "      <th>trigram_('a', 'broader', 'context')</th>\n",
       "      <th>trigram_('a', 'can', 'avoid')</th>\n",
       "      <th>trigram_('a', 'central', 'part')</th>\n",
       "      <th>trigram_('a', 'certain', 'predefined')</th>\n",
       "      <th>trigram_('a', 'class', 'can')</th>\n",
       "      <th>trigram_('a', 'classifier', 'can')</th>\n",
       "      <th>...</th>\n",
       "      <th>tags_('WRB', 'NNS', 'VBD')</th>\n",
       "      <th>tags_('WRB', 'PRP', 'VBP')</th>\n",
       "      <th>tags_('WRB', 'PRP', 'VBZ')</th>\n",
       "      <th>tags_('WRB', 'PRP$', 'NNS')</th>\n",
       "      <th>tags_('WRB', 'RB', 'PRP')</th>\n",
       "      <th>tags_('WRB', 'TO', 'VB')</th>\n",
       "      <th>tags_('WRB', 'VBD', 'CC')</th>\n",
       "      <th>tags_('WRB', 'VBG', 'DT')</th>\n",
       "      <th>tags_('WRB', 'VBG', 'NN')</th>\n",
       "      <th>tags_('WRB', 'VBN', 'DT')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trigram_('a', 'bad', 'overly')  trigram_('a', 'bayesian', 'network')  \\\n",
       "0                               0                                     0   \n",
       "1                               0                                     0   \n",
       "2                               0                                     0   \n",
       "3                               0                                     0   \n",
       "4                               0                                     0   \n",
       "\n",
       "   trigram_('a', 'best', 'guess')  trigram_('a', 'billion', 'dollars')  \\\n",
       "0                               0                                    0   \n",
       "1                               0                                    0   \n",
       "2                               0                                    0   \n",
       "3                               0                                    0   \n",
       "4                               0                                    0   \n",
       "\n",
       "   trigram_('a', 'broader', 'context')  trigram_('a', 'can', 'avoid')  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "\n",
       "   trigram_('a', 'central', 'part')  trigram_('a', 'certain', 'predefined')  \\\n",
       "0                                 0                                       0   \n",
       "1                                 0                                       0   \n",
       "2                                 0                                       0   \n",
       "3                                 0                                       0   \n",
       "4                                 0                                       0   \n",
       "\n",
       "   trigram_('a', 'class', 'can')  trigram_('a', 'classifier', 'can')  ...  \\\n",
       "0                              0                                   0  ...   \n",
       "1                              0                                   0  ...   \n",
       "2                              0                                   0  ...   \n",
       "3                              0                                   0  ...   \n",
       "4                              0                                   0  ...   \n",
       "\n",
       "   tags_('WRB', 'NNS', 'VBD')  tags_('WRB', 'PRP', 'VBP')  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   tags_('WRB', 'PRP', 'VBZ')  tags_('WRB', 'PRP$', 'NNS')  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   tags_('WRB', 'RB', 'PRP')  tags_('WRB', 'TO', 'VB')  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   tags_('WRB', 'VBD', 'CC')  tags_('WRB', 'VBG', 'DT')  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   tags_('WRB', 'VBG', 'NN')  tags_('WRB', 'VBN', 'DT')  \n",
       "0                          0                          0  \n",
       "1                          0                          0  \n",
       "2                          0                          0  \n",
       "3                          0                          0  \n",
       "4                          0                          0  \n",
       "\n",
       "[5 rows x 9005 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.get_dummies(df, columns=['trigram', 'tags'], drop_first=True)\n",
    "df2 = df2.drop(columns=['pred'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df2)\n",
    "y = np.asarray([feats.index(label) for label in df['pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "count_model = linear_model.LogisticRegression(multi_class='multinomial',solver='newton-cg',n_jobs=-1)\n",
    "count_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'savefiles/wordmaxent.pkl'\n",
    "# joblib.dump(count_model, filename)\n",
    "# filename = 'savefiles/tagmaxent.pkl'\n",
    "# joblib.dump(tag_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_model = joblib.load('savefiles/wordmaxent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_word_to_prediction(inp):\n",
    "    inp = nltk.word_tokenize(inp)\n",
    "    trigram = list(ngrams(inp,3))[0]\n",
    "    tags = ((nltk.pos_tag(inp)[0])[1],(nltk.pos_tag(inp)[1])[1], (nltk.pos_tag(inp)[2])[1])\n",
    "    vectordf = pd.DataFrame(0, index=[0], columns=df2.columns)\n",
    "    col_names = [('trigram_'+str(trigram)),('tags_'+str(tags))]\n",
    "    vectordf = vectordf.replace({col_names[0]: 0, col_names[1]: 0}, 1)\n",
    "    X = vectordf.to_numpy()\n",
    "    possible_predictions = count_model.predict_proba(X)[0]\n",
    "    indices = (-possible_predictions).argsort()[:3]\n",
    "    print(indices)\n",
    "    return [feats[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sent):\n",
    "    out = sent\n",
    "    for i in range(16):\n",
    "        print(out)\n",
    "        pred = input_word_to_prediction(sent) #prediction_union(sent)[0]\n",
    "        print(\"enter next word from predictions: \",pred)\n",
    "        inp = input()\n",
    "        out+= \" \" +inp\n",
    "        sent = \" \".join(nltk.word_tokenize(sent)[1:]+[inp])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai research is\n",
      "[14 70 15]\n",
      "enter next word from predictions:  ['to', 'a', 'the']\n",
      "the\n",
      "ai research is the\n",
      "[15 14  3]\n",
      "enter next word from predictions:  ['the', 'to', 'artificial']\n",
      "artificial\n",
      "ai research is the artificial\n",
      "[ 14  15 205]\n",
      "enter next word from predictions:  ['to', 'the', 'neural']\n",
      "neural\n",
      "ai research is the artificial neural\n",
      "[34 15 14]\n",
      "enter next word from predictions:  ['and', 'the', 'to']\n",
      "to\n",
      "ai research is the artificial neural to\n",
      "[15 14 34]\n",
      "enter next word from predictions:  ['the', 'to', 'and']\n",
      "and\n",
      "ai research is the artificial neural to and\n",
      "[15 30 14]\n",
      "enter next word from predictions:  ['the', 'that', 'to']\n"
     ]
    }
   ],
   "source": [
    "run(\"ai research is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec = Word2Vec([words], min_count=2)\n",
    "# vocabulary = word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 = word2vec.wv['artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_words = word2vec.wv.most_similar('artificial')\n",
    "# print(sim_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
